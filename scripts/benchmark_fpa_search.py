"""
FPA & Similar Query P95 Benchmark
"""
import time
import statistics
from pathlib import Path
from datetime import date, timedelta
import random

print('='*60)
print('üìä FPA & SIMILAR QUERY BENCHMARK')
print('='*60)

# ====================
# 1. FPA TRACKER TEST
# ====================
print()
print('1Ô∏è‚É£  FPA TRACKER TEST')
print('-'*40)

from priqualis.shadow.fpa import FPATracker, RejectionRecord

tracker = FPATracker()

# Simulate 5 batch submissions (100 cases each)
print('   Simulating 5 batch submissions (100 cases each)...')
all_case_ids = []
for batch_num in range(5):
    case_ids = [f'ENC{batch_num:02d}{i:03d}' for i in range(100)]
    all_case_ids.extend(case_ids)
    tracker.record_submission(
        batch_id=f'BATCH_{batch_num:03d}',
        case_ids=case_ids,
        submission_date=date.today() - timedelta(days=batch_num),
    )

# Simulate some rejections (15% = 75 rejections)
print('   Simulating 75 rejections (15%)...')
rejected_ids = random.sample(all_case_ids, 75)
rejections = []
for case_id in rejected_ids:
    rejections.append(RejectionRecord(
        case_id=case_id,
        rejection_date=date.today(),
        error_code=random.choice(['CWV_001', 'CWV_002', 'CWV_003', 'CWV_010']),
        error_message='Test rejection',
        rule_id=random.choice(['R001', 'R002', 'R003', 'R004']),
    ))
tracker.record_rejections(rejections)

# Calculate FPA
fpa_report = tracker.calculate_fpa()
print(f'   Total submitted: {fpa_report.total_submitted}')
print(f'   Total rejected: {fpa_report.total_rejected}')
print(f'   Total accepted: {fpa_report.total_accepted}')
print(f'   FPA Rate: {fpa_report.fpa_rate:.1%}')
print(f'   ‚úÖ FPATracker works correctly!')

# ====================
# 2. SIMILAR QUERY P95
# ====================
print()
print('2Ô∏è‚É£  SIMILAR QUERY P95 BENCHMARK')
print('-'*40)

from priqualis.search.bm25 import BM25Index
import polars as pl

# Build index from approved claims
print('   Building BM25 index from approved claims...')

df = pl.read_parquet('data/processed/claims_approved.parquet')

# Create searchable text for each claim
documents = []
for row in df.iter_rows(named=True):
    text = f"{row.get('jgp_code', '')} {row.get('icd10_main', '')} {row.get('department_code', '')}".strip()
    if text:
        documents.append((row['case_id'], text))

print(f'   Documents to index: {len(documents)}')

index = BM25Index()
start = time.perf_counter()
index.build(documents)
build_time = time.perf_counter() - start
print(f'   Index build time: {build_time:.2f}s')

# Run 100 queries and measure latency
print('   Running 100 test queries...')
query_times = []
test_queries = [
    'A01 J18.9 4000',
    'B02 E11.9 5000',
    'C01 I10 4500',
    'A02 J44.9 4000',
    'B01 I21.9 5000',
]

for _ in range(100):
    query = random.choice(test_queries)
    start = time.perf_counter()
    results = index.search(query, top_k=10)
    elapsed = (time.perf_counter() - start) * 1000  # ms
    query_times.append(elapsed)

p50 = statistics.median(query_times)
p95 = sorted(query_times)[94]  # 95th percentile
p99 = sorted(query_times)[98]  # 99th percentile
avg = statistics.mean(query_times)

print(f'   Query latency:')
print(f'     P50: {p50:.2f}ms')
print(f'     P95: {p95:.2f}ms')
print(f'     P99: {p99:.2f}ms')
print(f'     Avg: {avg:.2f}ms')
target_pass = "‚úÖ PASS" if p95 < 300 else "‚ùå FAIL"
print(f'   Target: <300ms ‚Üí {target_pass}')

# ====================
# SUMMARY
# ====================
print()
print('='*60)
print('üìã FINAL RESULTS')
print('='*60)
print(f'‚úÖ FPA Rate: {fpa_report.fpa_rate:.1%} (with 15% simulated rejections)')
print(f'‚úÖ Similar Query P95: {p95:.2f}ms (target <300ms)')
