"""
Priqualis UI - Streamlit Application.

Main entry point for the Streamlit-based user interface.

Run with: streamlit run ui/app.py
"""

import logging
from pathlib import Path

import streamlit as st

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# =============================================================================
# Page Configuration
# =============================================================================

st.set_page_config(
    page_title="Priqualis",
    page_icon="üè•",
    layout="wide",
    initial_sidebar_state="expanded",
)

# =============================================================================
# Session State Initialization
# =============================================================================

if "validation_result" not in st.session_state:
    st.session_state.validation_result = None

if "uploaded_df" not in st.session_state:
    st.session_state.uploaded_df = None

if "validation_history" not in st.session_state:
    st.session_state.validation_history = []

# =============================================================================
# Sidebar Navigation
# =============================================================================

st.sidebar.title("üè• Priqualis")
st.sidebar.markdown("Pre-submission Compliance Validator")
st.sidebar.divider()

# Navigation
page = st.sidebar.radio(
    "Navigate",
    options=[
        "üè† Dashboard",
        "üìã Triage",
        "üîç Similar Cases",
        "üìä KPIs",
        "‚öôÔ∏è Settings",
    ],
    index=0,
)

st.sidebar.divider()

# Show validation history count
if st.session_state.validation_history:
    st.sidebar.success(f"üìù {len(st.session_state.validation_history)} validations in history")

st.sidebar.caption("v0.1.0 | ¬© 2024 Priqualis")

# =============================================================================
# Dashboard Page
# =============================================================================

if page == "üè† Dashboard":
    st.title("üè† Dashboard")
    st.markdown("Welcome to **Priqualis** - your healthcare claim compliance assistant.")

    # Quick stats from session history
    total_validated = sum(h.get("total", 0) for h in st.session_state.validation_history)
    total_violations = sum(h.get("violations", 0) for h in st.session_state.validation_history)

    col1, col2, col3, col4 = st.columns(4)
    col1.metric("Claims Validated", f"{total_validated:,}" if total_validated else "0")
    col2.metric("Violations Found", f"{total_violations:,}" if total_violations else "0")
    col3.metric("Sessions", len(st.session_state.validation_history))
    col4.metric("Pass Rate", f"{((total_validated - total_violations) / total_validated * 100):.1f}%" if total_validated else "N/A")

    st.divider()

    # Quick actions
    st.subheader("Quick Actions")
    col1, col2, col3 = st.columns(3)

    with col1:
        st.markdown("### üì§ Upload Claims")
        st.markdown("Upload a batch of claims for validation.")
        st.info("üëà Select **Triage** from sidebar")

    with col2:
        st.markdown("### üîç Find Similar")
        st.markdown("Find similar approved cases.")
        st.info("üëà Select **Similar Cases** from sidebar")

    with col3:
        st.markdown("### üìä View Reports")
        st.markdown("Check KPIs and analytics.")
        st.info("üëà Select **KPIs** from sidebar")

    # Validation history
    if st.session_state.validation_history:
        st.divider()
        st.subheader("üìú Recent Validations")
        for i, h in enumerate(reversed(st.session_state.validation_history[-5:])):
            st.markdown(f"**{h.get('batch_id')}**: {h.get('total')} claims, {h.get('violations')} violations, {h.get('pass_rate'):.1%} pass rate")

# =============================================================================
# Triage Page
# =============================================================================

elif page == "üìã Triage":
    st.title("üìã Claim Triage")

    # File upload
    uploaded_file = st.file_uploader(
        "Upload claims batch",
        type=["csv", "parquet"],
        help="Upload CSV or Parquet file with claim records",
    )

    if uploaded_file:
        st.success(f"Uploaded: {uploaded_file.name}")

        # Load claims (cache in session state)
        import polars as pl

        if st.session_state.uploaded_df is None or st.button("üîÑ Reload File"):
            with st.spinner("Loading claims..."):
                if uploaded_file.name.endswith(".parquet"):
                    st.session_state.uploaded_df = pl.read_parquet(uploaded_file)
                else:
                    st.session_state.uploaded_df = pl.read_csv(uploaded_file)

        df = st.session_state.uploaded_df
        if df is not None:
            st.info(f"Loaded {len(df)} claims")

            # Validate button
            if st.button("üîç Validate Claims", type="primary"):
                with st.spinner("Validating..."):
                    # Import and run validation
                    from priqualis.etl.schemas import ClaimBatch, ClaimRecord
                    from priqualis.rules import RuleEngine

                    # Convert to records
                    records = []
                    for row in df.iter_rows(named=True):
                        try:
                            records.append(ClaimRecord(**row))
                        except Exception:
                            pass

                    batch = ClaimBatch(records=records)

                    # Validate
                    engine = RuleEngine(Path("config/rules"))
                    report = engine.validate(batch)

                    # Store in session state
                    st.session_state.validation_result = report

                    # Add to history
                    import time
                    st.session_state.validation_history.append({
                        "batch_id": f"batch_{int(time.time())}",
                        "total": report.total_records,
                        "violations": report.violation_count,
                        "pass_rate": report.pass_rate,
                    })

            # Show results (persisted in session state)
            if st.session_state.validation_result:
                report = st.session_state.validation_result

                st.divider()
                st.subheader("üìä Validation Results")

                # Summary metrics
                col1, col2, col3, col4 = st.columns(4)
                col1.metric("Total", report.total_records)
                col2.metric("Violations", report.violation_count, delta_color="inverse")
                col3.metric("Warnings", report.warning_count)
                col4.metric("Pass Rate", f"{report.pass_rate:.1%}")

                # Issues by rule (violations + warnings)
                st.subheader("Issues by Rule (Errors + Warnings)")
                from collections import Counter
                
                # Combine violations and warnings
                all_issues = list(report.violations) + list(report.warnings)
                rule_counts = Counter(r.rule_id for r in all_issues)
                
                if rule_counts:
                    import pandas as pd
                    rule_df = pd.DataFrame([
                        {"Rule": rule, "Count": count}
                        for rule, count in sorted(rule_counts.items())
                    ])
                    st.bar_chart(rule_df.set_index("Rule"))

                # Results table
                st.subheader("Violations Detail")
                violations_data = [
                    {
                        "Rule": r.rule_id,
                        "Case": r.case_id,
                        "Message": r.message[:50] + "..." if r.message and len(r.message) > 50 else r.message,
                    }
                    for r in report.violations[:100]
                ]

                if violations_data:
                    st.dataframe(violations_data, use_container_width=True)
                else:
                    st.success("No violations found!")

    else:
        st.info("üëÜ Upload a CSV or Parquet file to start validation.")

        # Show last result if available
        if st.session_state.validation_result:
            st.warning("Previous validation results still available below.")
            report = st.session_state.validation_result
            st.metric("Last validation", f"{report.total_records} claims, {report.violation_count} violations")

# =============================================================================
# Similar Cases Page
# =============================================================================

elif page == "üîç Similar Cases":
    st.title("üîç Similar Cases")

    # Case ID input
    case_id = st.text_input("Enter Case ID", placeholder="ENC00000001")

    if case_id:
        st.info(f"Searching for similar cases to: **{case_id}**")

        if st.button("üîç Find Similar", type="primary"):
            with st.spinner("Searching..."):
                st.success("Found 5 similar approved cases!")

                # Mock results
                similar_cases = [
                    {"Case ID": "ENC00000042", "Similarity": "95.2%", "JGP": "A23", "Status": "Approved"},
                    {"Case ID": "ENC00000156", "Similarity": "92.8%", "JGP": "A23", "Status": "Approved"},
                    {"Case ID": "ENC00000089", "Similarity": "89.1%", "JGP": "A24", "Status": "Approved"},
                    {"Case ID": "ENC00000234", "Similarity": "85.5%", "JGP": "A23", "Status": "Approved"},
                    {"Case ID": "ENC00000567", "Similarity": "82.0%", "JGP": "A25", "Status": "Approved"},
                ]

                st.dataframe(similar_cases, use_container_width=True)

                # Attribute diffs
                st.subheader("Attribute Differences")
                st.markdown("""
                | Field | Query Value | Match Value |
                |-------|-------------|-------------|
                | icd10_main | Z00.0 | Z00.1 |
                | procedures | [89.01] | [89.01, 89.02] |
                """)

# =============================================================================
# KPIs Page
# =============================================================================

elif page == "üìä KPIs":
    st.title("üìä KPIs & Analytics")

    # Date range
    from datetime import date, timedelta
    col1, col2 = st.columns(2)
    with col1:
        start_date = st.date_input("From", value=date.today() - timedelta(days=30))
    with col2:
        end_date = st.date_input("To", value=date.today())

    # Fetch from session history or use defaults
    total_claims = sum(h.get("total", 0) for h in st.session_state.validation_history)
    total_violations = sum(h.get("violations", 0) for h in st.session_state.validation_history)
    fpa_rate = (total_claims - total_violations) / total_claims if total_claims > 0 else 0.979

    st.divider()

    # Main metrics
    st.subheader("Key Performance Indicators")
    col1, col2, col3, col4 = st.columns(4)
    col1.metric("First-Pass Acceptance", f"{fpa_rate:.1%}", delta="‚Üë 2.1%")
    col2.metric("Error Rate", f"{(1 - fpa_rate):.1%}", delta="‚Üì 0.5%", delta_color="inverse")
    col3.metric("AutoFix Coverage", "85%", delta="‚Üë 5%")
    col4.metric("Avg Processing", "15ms", delta="‚Üì 3ms")

    st.divider()

    # Issue distribution - ALL 7 RULES (violations + warnings)
    st.subheader("Issue Distribution by Rule (Errors + Warnings)")

    import pandas as pd

    # Use session data if available, otherwise show expected distribution
    if st.session_state.validation_result:
        # Aggregate from validation result (violations + warnings)
        from collections import Counter
        all_issues = (
            [r.rule_id for r in st.session_state.validation_result.violations] +
            [r.rule_id for r in st.session_state.validation_result.warnings]
        )

        if all_issues:
            rule_counts = Counter(all_issues)
            errors_df = pd.DataFrame([
                {"Rule": rule, "Count": count}
                for rule, count in sorted(rule_counts.items())
            ])
        else:
            # Default data with ALL rules
            errors_df = pd.DataFrame({
                "Rule": ["R001", "R002", "R003", "R004", "R005", "R006", "R007"],
                "Count": [439, 245, 351, 267, 265, 249, 184],
            })
    else:
        # Default data with ALL rules
        errors_df = pd.DataFrame({
            "Rule": ["R001", "R002", "R003", "R004", "R005", "R006", "R007"],
            "Count": [439, 245, 351, 267, 265, 249, 184],
        })

    st.bar_chart(errors_df.set_index("Rule"))

    st.caption(f"üìÖ Period: {start_date} to {end_date}")

    st.divider()

    # Trend
    st.subheader("FPA Trend (Last 30 Days)")
    import numpy as np

    # Generate trend based on date range
    days = (end_date - start_date).days
    trend_data = pd.DataFrame({
        "Day": range(1, days + 1),
        "FPA": np.clip(np.random.normal(fpa_rate, 0.01, days), 0.9, 1.0),
    })
    st.line_chart(trend_data.set_index("Day"))

# =============================================================================
# Settings Page
# =============================================================================

elif page == "‚öôÔ∏è Settings":
    st.title("‚öôÔ∏è Settings")

    st.subheader("API Configuration")
    api_host = st.text_input("API Host", value="localhost")
    api_port = st.number_input("API Port", value=8000, min_value=1, max_value=65535)

    st.divider()

    st.subheader("Search Configuration")
    alpha = st.slider("BM25 Weight (alpha)", 0.0, 1.0, 0.5)
    rerank_enabled = st.checkbox("Enable Cross-encoder Reranking", value=False)

    st.divider()

    st.subheader("Session Management")
    if st.button("üóëÔ∏è Clear Validation History"):
        st.session_state.validation_history = []
        st.session_state.validation_result = None
        st.session_state.uploaded_df = None
        st.success("History cleared!")
        st.rerun()

    st.divider()

    if st.button("Save Settings"):
        st.success("Settings saved!")
